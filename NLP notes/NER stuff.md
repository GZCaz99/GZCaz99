## NER 实体命名
NER是NLP中的常见任务,输入为一串文本,期望输出为文本中的实体. 任务的实现通过几种不同的字符标注方法来识别出实体的范围及类别,常见的标注体系有:
> BIO: 即B-实体开始的位置,I-实体中间元素,O-其他元素
> 
> BIOE:同上,除了E-实体结束位置
> 
> BIOES:同上,除了S-表示某个单字符自己组成一个实体

现实中NER的实现一般通过下面三种方法;

> 基于人工标注的数据/规则,比如正则表达式来识别关键字
>
> 基于已有字典的数据, 比如{'市医院':['附属中医院','附属眼科医院']}
>
> 基于各类模型, 比如 BI-LSTM+ CRF, BERT+CRF等

#### 基于模型的NER
基于模型的NER已被证明是相当有效的实现路径,这里重点记录CRF/HMM, BI-LSTM/BERT/Transformer 这两类模型在NER中的作用
> 这篇文章有一些NER工作上常见问题的解决方法: https://cloud.tencent.com/developer/article/2034615

##### Bi-LSTM + CRF
假设在一个简单任务中, 我们使用BIO的标注方式, 这其中又有 B-org,B-per 两个子标签来表示组织和个人,那么对应的就有 I-org 和 I-per两个额外标签(总共5个). 同时输入为一个5个单词的句子, 那么训练流程为:
- 输入根据文本生成的词向量和字向量,其中字向量一般是随即初始化的
- 各类向量输入进入Bi-lstm层进行训练,输出为1 x K的 向量,其中k 为标签数量,在这个例子里就是5.向量中每一列的值对应着当前单词/字为某个标签的概率
- lstm的输出即为CRF的输入,我们通过加入CRF层的约束来获得更加合理的结果

而在CRF层中的损失函数中,有两种主要的分数: 
1. Emission score , 这分数就是上文中lstm输出的 1 x k 向量中每一行的值,对于这个例子,我们用 Ew0^i0 来表示第一个词经lstm预测的属于第一个标签的值,同样的对于每个词,我们都有k个emission score
2. Transition Score, 通过CRF训练得到,表示模型学习到的从上一个特定标签转移为下一个特定标签的概率
  



效果评估:
NER模型中最看重的就是Recall和Precision







